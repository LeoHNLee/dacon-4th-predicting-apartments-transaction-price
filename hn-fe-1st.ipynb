{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE 1st\n",
    "\n",
    "- 확인한 내용들 : hn-eda-prep 커널의 뒷부분 additional topic에서 불친절하게 확인할 수 있음\n",
    "    - 단지별 가격분포가 얼마나 강력하게 관여되는지\n",
    "    - 고층 건물이라서 비싼 건지, 집 층수가 높으면 비싼 건지\n",
    "        - 고층이면 비싼 경향이 확실히 있음\n",
    "        - 하지만 층수가 더 강력하고 선형적으로 가격에 관여함\n",
    "        - 더 생각해볼 점 : 층수 정보에서 고층빌딩/단지정보를 제거 해서 층수 정보만 남길 수 있는 방법이 있을까?\n",
    "    - 거래날짜 정보의 주기성 확인\n",
    "        - 주기성은 없다고 봄\n",
    "        - 중요도 : 연 >> 월 > 일\n",
    "        - 월에서 약간의 주기성이 보이는 듯 하나, 의미있는 변동은 아니라고 봄 <- 날짜 정보를 다룰 때 월을 분리해서 컬럼으로 사용하는 법도 검토해볼만 함\n",
    "- 바로 할 수 있는 것들만 먼저 적용\n",
    "    - 가격, 거래 날짜, 법정동코드를 활용한 시구동 핸들링, 면적 정보를 활용한 fe\n",
    "    - 이미 해본 거 같지만 아직 안 건든 부분도 있어보여서 나름 fe 시도 해봄\n",
    "- 가격 : log scaling\n",
    "- 거래 날짜 : 연/월/일, 연월일 단순합성(기존방법)\n",
    "    - 연월일 스케일링 : 10일 단위를 1로 보고, 월단위를 3, 연단위를 33으로 보고 1~462 범위의 int로 치환\n",
    "- 면적 정보\n",
    "    - 추가한 자료 : 공용면적, 전용률\n",
    "    - 사실 전용면적, 공용면적, 공급면적, 전용률이 단순 사칙연산의 관계이기 때문에, 전용면적과 공용면적만 사용해도 될 듯\n",
    "- 지역 정보\n",
    "    - city, 법정코드를 활용해서 서울/부산, 구, 동 정보 조합 시도\n",
    "- 1/7~8 중에 끝날 내용\n",
    "    - 아파트 아이디(단지 정보)를 어떻게 Cat 변수로 변환할 것인가 <- 어떻게 변환하느냐가 성능에 큰 영향을 미칠 것 같음\n",
    "    - Null data를 타겟 값으로 훈련시켜서 null값 채워넣기\n",
    "- 모델링 쪽에서 확인해줬으면 하는 점\n",
    "    - 거래 날짜 정보 : 거래 날짜 정보를 여러 가지 방법으로 조합해보았는데,\n",
    "        중복 컬럼이 되지 않게 (컬럼간 선형 또는 상관이 존재하지 않게) 특성 조합 퍼포먼스 점수랑 feature importance 확인\n",
    "        - 세 가지 방법 중 가장 나은 것 선택하는 게 좋을 듯\n",
    "    - 면적정보 : 전용면적과 공용면적만 사용하는게 나은지 확인\n",
    "    - 지역 정보\n",
    "        - city, district, town, disTown, cityDisTown의 여러 조합 실험이 필요할 듯\n",
    "        - 시,구,동 정보가 중복되서 들어가지 않게 조절해야 할 듯\n",
    "- 오늘 작업 내용의 한계\n",
    "    - 단일 컬럼과 가격과의 2차원 그래프만 보면서 확인했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, warnings, re, time, gc\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append(os.path.abspath(os.path.dirname('../')))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = './datasets/origin/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "subway = pd.read_csv(path+'Subways.csv')\n",
    "school = pd.read_csv(path+'Schools.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연산용 코드 모음\n",
    "\n",
    "train['logPrice']=np.log(train['transaction_real_price'])\n",
    "\n",
    "train['transYear'] = train['transaction_year_month'].apply(lambda row : int(str(row)[:4]))\n",
    "train['transMonth'] = train['transaction_year_month'].apply(lambda row : int(str(row)[4:]))\n",
    "train['transDate'] = train['transaction_date'].apply(lambda row : int(row.split('~')[0]))\n",
    "test['transYear'] = test['transaction_year_month'].apply(lambda row : int(str(row)[:4]))\n",
    "test['transMonth'] = test['transaction_year_month'].apply(lambda row : int(str(row)[4:]))\n",
    "test['transDate'] = test['transaction_date'].apply(lambda row : int(row.split('~')[0]))\n",
    "\n",
    "def transYMD(row):\n",
    "    ym = str(row['transaction_year_month'])\n",
    "    date = str(row['transDate'])\n",
    "    if len(date)==1 : date = '0'+date\n",
    "    return int(ym+date)\n",
    "train['transYMD'] = train.apply(lambda row : transYMD(row), axis=1)\n",
    "test['transYMD'] = test.apply(lambda row : transYMD(row), axis=1)\n",
    "\n",
    "def transOdered(row):\n",
    "    data = str(row)\n",
    "    year = data[:4]\n",
    "    month = data[4:6]\n",
    "    date = data[6:]\n",
    "    if date == '01' : date = 1\n",
    "    elif date == '11' : date = 2\n",
    "    else : date = 3\n",
    "    month = (int(month)-1)*3\n",
    "    year = (int(year)-2006)*36\n",
    "    return year+month+date\n",
    "train['transOrdered'] = train['transYMD'].apply(lambda row : transOdered(row))\n",
    "test['transOrdered'] = test['transYMD'].apply(lambda row : transOdered(row))\n",
    "\n",
    "train['commonArea'] = train.apply(lambda row : row['supply_area']-row['exclusive_use_area'], axis=1)\n",
    "test['commonArea'] = test.apply(lambda row : row['supply_area']-row['exclusive_use_area'], axis=1)\n",
    "train['areaRate'] = train.apply(lambda row : row[exclu]/row[supply], axis=1)\n",
    "test['areaRate'] = test.apply(lambda row : row[exclu]/row[supply], axis=1)\n",
    "\n",
    "train['district'] = train['address_by_law'].apply(lambda row : int(str(row)[2:5]))\n",
    "test['district'] = test['address_by_law'].apply(lambda row : int(str(row)[2:5]))\n",
    "train['town'] = train['address_by_law'].apply(lambda row : int(str(row)[5:8]))\n",
    "test['town'] = test['address_by_law'].apply(lambda row : int(str(row)[5:8]))\n",
    "train['disTown'] = train.apply(lambda row : int(str(row['district'])+str(row['town'])), axis=1)\n",
    "test['disTown'] = test.apply(lambda row : int(str(row['district'])+str(row['town'])), axis=1)\n",
    "train['cityDisTown'] = train.apply(lambda row : int(str(row['city'])+str(row['disTown'])), axis=1)\n",
    "test['cityDisTown'] = test.apply(lambda row : int(str(row['city'])+str(row['disTown'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './datasets'\n",
    "# train.to_csv(path+'trainFe1st.csv',index=False)\n",
    "# test.to_csv(path+'testFe1st.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중요 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 로그 스케일링\n",
    "target = 'logPrice'\n",
    "train[target]=np.log(train['transaction_real_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아파트 아이디 가격에 따라 정렬해서 int로 캐스팅 : 순서가 있는 카테고리\n",
    "# apart = \n",
    "# uniqId = train['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간 정보\n",
    "\n",
    "- 데이터를 살펴보니까, 굳이 날짜정보를 합성해서 쓸 필요가 없을 것 같음\n",
    "- 중요도 : 연 >> 월 > 일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 정보 분리\n",
    "train['transYear'] = train['transaction_year_month'].apply(lambda row : int(str(row)[:4]))\n",
    "train['transMonth'] = train['transaction_year_month'].apply(lambda row : int(str(row)[4:]))\n",
    "train['transDate'] = train['transaction_date'].apply(lambda row : int(row.split('~')[0]))\n",
    "\n",
    "test['transYear'] = test['transaction_year_month'].apply(lambda row : int(str(row)[:4]))\n",
    "test['transMonth'] = test['transaction_year_month'].apply(lambda row : int(str(row)[4:]))\n",
    "test['transDate'] = test['transaction_date'].apply(lambda row : int(row.split('~')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20060101 20181021\n"
     ]
    }
   ],
   "source": [
    "# 날짜 정보 합성\n",
    "def transYMD(row):\n",
    "    ym = str(row['transaction_year_month'])\n",
    "    date = str(row['transDate'])\n",
    "    if len(date)==1 : date = '0'+date\n",
    "    return int(ym+date)\n",
    "    \n",
    "train['transYMD'] = train.apply(lambda row : transYMD(row), axis=1)\n",
    "test['transYMD'] = test.apply(lambda row : transYMD(row), axis=1)\n",
    "# print(len(train['transYMD'].unique()))\n",
    "transMin = min(train['transYMD'].min(), test['transYMD'].min())\n",
    "transMax = min(train['transYMD'].max(),test['transYMD'].max())\n",
    "print(transMin, transMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜정보 정규화\n",
    "def transOdered(row):\n",
    "    data = str(row)\n",
    "    year = data[:4]\n",
    "    month = data[4:6]\n",
    "    date = data[6:]\n",
    "    if date == '01' : date = 1\n",
    "    elif date == '11' : date = 2\n",
    "    else : date = 3\n",
    "    month = (int(month)-1)*3\n",
    "    year = (int(year)-2006)*36\n",
    "    return year+month+date\n",
    "train['transOrdered'] = train['transYMD'].apply(lambda row : transOdered(row))\n",
    "test['transOrdered'] = test['transYMD'].apply(lambda row : transOdered(row))\n",
    "\n",
    "# 정규화 / 단순 합성 / 연월일 분리 중 가장 영향력 높은 걸로 하나만 사용하는 게 나을 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train['transOrdered'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 건물/단지 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 집 정보\n",
    "### 면적 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclu = 'exclusive_use_area'\n",
    "supply = 'supply_area'\n",
    "roomid = 'room_id'\n",
    "# 공용면적\n",
    "train['commonArea'] = train.apply(lambda row : row[supply]-row[exclu], axis=1)\n",
    "test['commonArea'] = test.apply(lambda row : row[supply]-row[exclu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전용률 : 전용면적 / 전체 면적 = 전용면적의 비율\n",
    "train['areaRate'] = train.apply(lambda row : row[exclu]/row[supply], axis=1)\n",
    "test['areaRate'] = test.apply(lambda row : row[exclu]/row[supply], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parking = 'total_parking_capacity_in_site'\n",
    "# lowest = 'lowest_building_in_sites'\n",
    "# tallest = 'tallest_building_in_sites'\n",
    "# front = 'front_door_structure'\n",
    "room = 'room_count'\n",
    "bath = 'bathroom_count'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'heat_type', 'heat_fuel'\n",
    "train['heat_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 위치 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구 정보 : 3~5\n",
    "train['district'] = train['address_by_law'].apply(lambda row : int(str(row)[2:5]))\n",
    "test['district'] = test['address_by_law'].apply(lambda row : int(str(row)[2:5]))\n",
    "\n",
    "# 동 정보 : 6~8\n",
    "train['town'] = train['address_by_law'].apply(lambda row : int(str(row)[5:8]))\n",
    "test['town'] = test['address_by_law'].apply(lambda row : int(str(row)[5:8]))\n",
    "\n",
    "# 구+동 정보 : 그냥 동정보/구정보 보다 더 정확할 수 있다.\n",
    "# 왜냐하면, 지역별 땅값은 사실 '구'보다 '동'이 더 영향력이 큼, 구는 좀 뭉뚱그려지는 느낌\n",
    "train['disTown'] = train.apply(lambda row : int(str(row['district'])+str(row['town'])), axis=1)\n",
    "test['disTown'] = test.apply(lambda row : int(str(row['district'])+str(row['town'])), axis=1)\n",
    "\n",
    "# 실험해 볼만한 것 : 앞에 시 정보도 삽입하자\n",
    "train['cityDisTown'] = train.apply(lambda row : int(str(row['city'])+str(row['disTown'])), axis=1)\n",
    "test['cityDisTown'] = test.apply(lambda row : int(str(row['city'])+str(row['disTown'])), axis=1)\n",
    "\n",
    "# 얘들은 Cat Data임을 명심하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['areaRate'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-65b7902e74d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m '''\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropCols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropCols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3111\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4404\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['areaRate'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# dropCols = ['transaction_date','transaction_year_month', 'room_id','address_by_law','latitude', 'longitude',\n",
    "#            'supply_area', 'areaRate','total_parking_capacity_in_site', 'lowest_building_in_sites',\n",
    "#             'tallest_building_in_sites','front_door_structure',]\n",
    "'''\n",
    "room id : 데이터 상태가 뭔가 이상함=면적과 불일치함, 집 크기에 관한 정보는 면적 정보로 충분함\n",
    "시간, 위치 정보 : 세분화가 되어서 중복/불필요해진 데이터\n",
    "위/경도 : 거의 단지별로 유일함 <- 굳이 중복해서 이용할 필요가 없음\n",
    "지역 정보 : 가장 좋은 조합만 사용\n",
    "면적 정보 : \n",
    "low importances : 단지 정보에 딸려 있는 정보들 좀 제외하고 쓰면 더 나을 수도\n",
    "'''\n",
    "# train = train.drop(columns=dropCols)\n",
    "# test = test.drop(columns=dropCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'apartment_id', 'city', 'transaction_year_month',\n",
       "       'transaction_date', 'year_of_completion', 'exclusive_use_area', 'floor',\n",
       "       'latitude', 'longitude', 'address_by_law',\n",
       "       'total_parking_capacity_in_site', 'total_household_count_in_sites',\n",
       "       'apartment_building_count_in_sites', 'tallest_building_in_sites',\n",
       "       'lowest_building_in_sites', 'heat_type', 'heat_fuel', 'room_id',\n",
       "       'supply_area', 'total_household_count_of_area_type', 'room_count',\n",
       "       'bathroom_count', 'front_door_structure', 'transaction_real_price',\n",
       "       'transYear', 'transMonth', 'transDate', 'transYMD', 'transOrdered',\n",
       "       'commonArea', 'areaRate', 'district', 'town', 'disTown', 'cityDisTown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
